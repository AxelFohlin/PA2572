{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df80989",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_2', 'score': 0.9889271259307861}]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForSequenceClassification, pipeline\n",
    "\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model_name)\n",
    "# config = AutoConfig.from_pretrained(model_name)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "label_map = {\n",
    "    'LABEL_0': 'NEGATIVE',\n",
    "    'LABEL_1': 'NEUTRAL',\n",
    "    'LABEL_2': 'POSITIVE'\n",
    "}\n",
    "\n",
    "from langdetect import detect\n",
    "from langdetect.lang_detect_exception import LangDetectException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1d9f19c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html(text):\n",
    "    clean = re.sub(r'<[^>]+>', ' ', text)\n",
    "    return re.sub(r'\\s+', ' ', clean).strip()\n",
    "\n",
    "def clean_review(text):\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "    text = remove_html(text)\n",
    "    return text\n",
    "\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except LangDetectException:\n",
    "        return \"error\"\n",
    "\n",
    "\n",
    "def classify_sentiment(text):\n",
    "    try:\n",
    "        return label_map[classifier(text[:514])[0]['label']]\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing: {text[:60]}... -> {e}\")\n",
    "        return \"error\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6d7c3c",
   "metadata": {},
   "source": [
    "* PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "78741d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/reviews.csv\")\n",
    "df.dropna(subset=['comments'], inplace=True)\n",
    "\n",
    "df['comments'] = df['comments'].apply(clean_review)\n",
    "\n",
    "df = df[df['comments'].apply(detect_language) == 'en']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing: 公寓地段非常好，距离最近的地铁站步行五分钟，去City Hall两站地铁，去Galma Stan三站地铁，去Vasa M... -> The expanded size of the tensor (583) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 583].  Tensor sizes: [1, 514]\n",
      "Error processing: 房間整潔，位置良好，離地鐵真的近，有電梯，附近生活機能還不錯 沒看清楚是我的疏失，對不起，廚房可以使用但是不能用爐子，就... -> The expanded size of the tensor (564) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 564].  Tensor sizes: [1, 514]\n",
      "Error processing: 저렴한 가격임에도 불구하고 진짜 너무 좋은 방이었어요. 지하철 2분거리에 웬만한 곳들은 지하철 30분 이내로... -> The expanded size of the tensor (517) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 517].  Tensor sizes: [1, 514]\n",
      "Error processing: Eva is very friendly and humorous. The house was more spacio... -> The expanded size of the tensor (528) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 528].  Tensor sizes: [1, 514]\n",
      "Error processing: One star I can give. 很糟糕的经历。1如果您是女生，你可能与来自不同国家的男人同住一间，可能是东亚，... -> The expanded size of the tensor (607) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 607].  Tensor sizes: [1, 514]\n",
      "Error processing: 很糟糕的经历。1如果您是女生，你可能与来自不同国家的男人同住一间，可能是东亚，印度，美国，欧洲，中东等等。只有当你住进去... -> The expanded size of the tensor (603) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 603].  Tensor sizes: [1, 514]\n"
     ]
    }
   ],
   "source": [
    "df['sentiment'] = df['comments'].apply(classify_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/sentiment_reviews.csv\", index=False)\n",
    "df[df['sentiment'] == 'NEGATIVE'][['comments', 'sentiment']].to_csv('data/negative_reviews.csv', index=False)\n",
    "df[df['sentiment'] == 'POSITIVE'][['comments', 'sentiment']].to_csv('data/positive_reviews.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
