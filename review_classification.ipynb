{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7cd078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForSequenceClassification, pipeline\n",
    "\n",
    "from langdetect import detect\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df80989",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model_name, device=0)\n",
    "\n",
    "\n",
    "label_map = {\n",
    "    'LABEL_0': 'NEGATIVE',\n",
    "    'LABEL_1': 'NEUTRAL',\n",
    "    'LABEL_2': 'POSITIVE'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9f19c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html(text):\n",
    "    clean = re.sub(r'<[^>]+>', ' ', text)\n",
    "    return re.sub(r'\\s+', ' ', clean).strip()\n",
    "\n",
    "def clean_review(text):\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "    text = remove_html(text)\n",
    "    return text\n",
    "\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except LangDetectException:\n",
    "        return \"error\"\n",
    "\n",
    "\n",
    "def classify_sentiment(text):\n",
    "    try:\n",
    "        return label_map[classifier(text[:514])[0]['label']]\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing: {text[:60]}... -> {e}\")\n",
    "        return \"error\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6d7c3c",
   "metadata": {},
   "source": [
    "2. **Preprocessing**  \n",
    "   Raw review data is loaded and cleaned:\n",
    "   - Read the CSV file: `data/reviews.csv`.\n",
    "   - Remove entries with missing comments.\n",
    "   - Apply `clean_review` to clean the review.\n",
    "   - Filter out reviews that are not written in English using `detect_language`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78741d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/reviews.csv\")\n",
    "df.dropna(subset=['comments'], inplace=True)\n",
    "\n",
    "df['comments'] = df['comments'].apply(clean_review)\n",
    "\n",
    "df = df[df['comments'].apply(detect_language) == 'en']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074ba328",
   "metadata": {},
   "source": [
    "3. **Sentiment Analysis**  \n",
    "   The cleaned and filtered English reviews are passed in batches to a Hugging Face transformer pipeline running on GPU to classify each review's sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115c3b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['comments'].str[:514].tolist()\n",
    "batch_size = 32\n",
    "results = []\n",
    "\n",
    "for i in tqdm(range(0, len(texts), batch_size), desc=\"Classifying\"):\n",
    "    batch = texts[i:i + batch_size]\n",
    "    try:\n",
    "        batch_results = classifier(batch)\n",
    "        batch_labels = [label_map.get(result['label'], 'unknown') for result in batch_results]\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch {i//batch_size}: {e}\")\n",
    "        batch_labels = ['error'] * len(batch)\n",
    "    results.extend(batch_labels)\n",
    "\n",
    "df['sentiment'] = results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a901f20",
   "metadata": {},
   "source": [
    "4. **Saving Results**  \n",
    "   The final dataset, including predicted sentiment labels, is saved. Additional filtering can be done to extract only positive or negative reviews for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39247c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['sentiment'] != 'NEUTRAL'].to_csv('data/sentiment_reviews.csv', index=False)\n",
    "df[df['sentiment'] == 'NEGATIVE'][['comments', 'sentiment']].to_csv('data/negative_reviews.csv', index=False)\n",
    "df[df['sentiment'] == 'POSITIVE'][['comments', 'sentiment']].to_csv('data/positive_reviews.csv', index=False)\n",
    "\n",
    "print(\"Sentiment classification completed and saved to sentiment_reviews.csv\")\n",
    "print(\"Negative reviews saved to negative_reviews.csv size:\", len(df[df['sentiment'] == 'NEGATIVE'].index))\n",
    "print(\"Positive reviews saved to positive_reviews.csv size:\", len(df[df['sentiment'] == 'POSITIVE'].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1d6e3c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listing = pd.read_csv(\"data/listings.csv.gz\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dcd7d5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5223, 75)\n",
      "Index(['id', 'listing_url', 'scrape_id', 'last_scraped', 'source', 'name',\n",
      "       'description', 'neighborhood_overview', 'picture_url', 'host_id',\n",
      "       'host_url', 'host_name', 'host_since', 'host_location', 'host_about',\n",
      "       'host_response_time', 'host_response_rate', 'host_acceptance_rate',\n",
      "       'host_is_superhost', 'host_thumbnail_url', 'host_picture_url',\n",
      "       'host_neighbourhood', 'host_listings_count',\n",
      "       'host_total_listings_count', 'host_verifications',\n",
      "       'host_has_profile_pic', 'host_identity_verified', 'neighbourhood',\n",
      "       'neighbourhood_cleansed', 'neighbourhood_group_cleansed', 'latitude',\n",
      "       'longitude', 'property_type', 'room_type', 'accommodates', 'bathrooms',\n",
      "       'bathrooms_text', 'bedrooms', 'beds', 'amenities', 'price',\n",
      "       'minimum_nights', 'maximum_nights', 'minimum_minimum_nights',\n",
      "       'maximum_minimum_nights', 'minimum_maximum_nights',\n",
      "       'maximum_maximum_nights', 'minimum_nights_avg_ntm',\n",
      "       'maximum_nights_avg_ntm', 'calendar_updated', 'has_availability',\n",
      "       'availability_30', 'availability_60', 'availability_90',\n",
      "       'availability_365', 'calendar_last_scraped', 'number_of_reviews',\n",
      "       'number_of_reviews_ltm', 'number_of_reviews_l30d', 'first_review',\n",
      "       'last_review', 'review_scores_rating', 'review_scores_accuracy',\n",
      "       'review_scores_cleanliness', 'review_scores_checkin',\n",
      "       'review_scores_communication', 'review_scores_location',\n",
      "       'review_scores_value', 'license', 'instant_bookable',\n",
      "       'calculated_host_listings_count',\n",
      "       'calculated_host_listings_count_entire_homes',\n",
      "       'calculated_host_listings_count_private_rooms',\n",
      "       'calculated_host_listings_count_shared_rooms', 'reviews_per_month'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_listing.shape)\n",
    "print(df_listing.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a6f78229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                                 0\n",
      "listing_url                                        0\n",
      "scrape_id                                          0\n",
      "last_scraped                                       0\n",
      "source                                             0\n",
      "                                                ... \n",
      "calculated_host_listings_count                     0\n",
      "calculated_host_listings_count_entire_homes        0\n",
      "calculated_host_listings_count_private_rooms       0\n",
      "calculated_host_listings_count_shared_rooms        0\n",
      "reviews_per_month                               1063\n",
      "Length: 75, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Missing values in df\n",
    "\n",
    "print(df_listing.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b773ab0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_bathroom_count(text):\n",
    "    if pd.isna(text):\n",
    "        return np.nan\n",
    "    text = str(text).lower().strip()\n",
    "    \n",
    "    if \"half\" in text:\n",
    "        return 0.5\n",
    "    match = re.search(r\"([\\d\\.]+)\", text)\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    return np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf88ec80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$944.00' '$414.00' '$1,320.00' ... '$484.00' '$1,820.00' '$20,000.00']\n",
      "['1 shared bath' '1 bath' '2 baths' '1.5 baths' '2 shared baths'\n",
      " 'Shared half-bath' '2.5 baths' '1.5 shared baths' nan '3 baths'\n",
      " '1 private bath' '3.5 baths' 'Half-bath' '2.5 shared baths'\n",
      " '0 shared baths' '3 shared baths' '4 shared baths' '4.5 baths' '0 baths'\n",
      " 'Private half-bath' '4 baths' '7.5 shared baths' '9 shared baths'\n",
      " '12 baths' '6 shared baths' '6 baths' '5.5 baths']\n",
      "9\n",
      "Index(['price', 'neighbourhood_cleansed', 'room_type', 'bedrooms',\n",
      "       'bathrooms_text', 'accommodates', 'amenities', 'minimum_nights',\n",
      "       'number_of_reviews', 'review_scores_rating', 'name', 'description',\n",
      "       'bathrooms'],\n",
      "      dtype='object')\n",
      "[  944.   414.  1320. ...   484.  1820. 20000.]\n",
      "[ 1.   2.   1.5  0.5  2.5  nan  3.   3.5  0.   4.   4.5  7.5  9.  12.\n",
      "  6.   5.5]\n"
     ]
    }
   ],
   "source": [
    "# Clean listing\n",
    "\n",
    "# Only use useful columns\n",
    "columns_to_keep = [\n",
    "    'price',\n",
    "    'neighbourhood_cleansed',\n",
    "    'room_type',\n",
    "    'bedrooms',\n",
    "    'bathrooms_text',\n",
    "    'accommodates',\n",
    "    'amenities',\n",
    "    'minimum_nights',\n",
    "    'number_of_reviews',\n",
    "    'review_scores_rating',\n",
    "    'name',\n",
    "    'description'\n",
    "]\n",
    "print(df_listing[\"price\"].unique())\n",
    "print(df_listing[\"bathrooms_text\"].unique())\n",
    "\n",
    "df_listing = df_listing[columns_to_keep].copy()\n",
    "# Logic to remove rows with missing important columns?\n",
    "\n",
    "# Price\n",
    "df_listing[\"price\"] = df_listing[\"price\"].replace('[\\$,]', '', regex=True).astype(float)\n",
    "# Convert bathroom text to numerical\n",
    "df_listing['bathrooms'] = df_listing['bathrooms_text'].apply(parse_bathroom_count)\n",
    "print(df_listing.columns)\n",
    "df_listing.drop([\"bathrooms_text\"], axis=1, inplace=True)\n",
    "\n",
    "print(df_listing[\"price\"].unique())\n",
    "print(df_listing[\"bathrooms\"].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
